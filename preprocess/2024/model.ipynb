{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 模型训练/调参/预测"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b23bf8db9c940a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T00:34:24.714751Z",
     "start_time": "2024-10-29T00:34:23.034266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from constant import *\n",
    "from sklearn.metrics import roc_curve\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "import lightgbm as lgb\n",
    "from data import loader,exporter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:16:31.480442Z",
     "start_time": "2024-10-28T14:16:31.474017Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 23,
   "source": [
    "def ks_stat(y_true, y_pred):\n",
    "    \"\"\"计算KS值的自定义评估函数\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)  # 计算ROC曲线\n",
    "    ks_value = np.max(np.abs(tpr - fpr))  # KS统计量\n",
    "    return ks_value\n",
    "\n",
    "\n",
    "def lgb_ks_eval(y_pred, dataset):\n",
    "    \"\"\"用于LightGBM的自定义KS评估函数\"\"\"\n",
    "    y_true = dataset.get_label()\n",
    "    ks_value = ks_stat(y_true, y_pred)\n",
    "    # 返回 (名称, 计算的 KS 值, 是否越高越好)\n",
    "    return 'ks', ks_value, True\n",
    "\n",
    "\n",
    "# 自定义目标函数，用于贝叶斯优化\n",
    "def objective(params, X, y, n_folds=5):\n",
    "    \"\"\"贝叶斯优化的目标函数，返回负的整体验证集KS分数\"\"\"\n",
    "    # 设置模型参数\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'binary'\n",
    "    params['verbose'] = -1\n",
    "    params['early_stopping_round'] = 20\n",
    "    params['n_estimators'] = 10000\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    # 存储每一折的预测结果\n",
    "    final_predictions = np.zeros(len(X))\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        # 建立LightGBM训练集\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "        # 训练LightGBM模型\n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_valid],\n",
    "                          feval=lgb_ks_eval,\n",
    "                          callbacks=[lgb.early_stopping(stopping_rounds=50),\n",
    "                                     lgb.log_evaluation(10)])\n",
    "\n",
    "        # 验证集预测概率\n",
    "        y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "        # 将每一折的预测结果填入到相应的索引位置\n",
    "        final_predictions[valid_idx] = y_pred\n",
    "\n",
    "    # 计算整体的KS分数\n",
    "    overall_score = ks_stat(y, final_predictions)\n",
    "\n",
    "    # 返回负的KS分数作为最小化目标\n",
    "    return {'loss': -overall_score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# 超参数空间\n",
    "param_space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),  # 学习率\n",
    "    'num_leaves': hp.choice('num_leaves', np.arange(20, 150, dtype=int)),  # 叶子数\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 12, dtype=int)),  # 树的最大深度\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.001, 10),  # 子叶节点的最小权重\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),  # 样本列采样率\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 1, 20),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),  # 样本采样率\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),  # L1正则化\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0)  # L2正则化\n",
    "}\n",
    "\n",
    "\n",
    "# 贝叶斯优化调参函数\n",
    "def bayesian_optimize_lgbm(X, y, param_space, max_evals=50):\n",
    "    trials = Trials()\n",
    "\n",
    "    # 使用fmin函数进行贝叶斯优化\n",
    "    best_params = fmin(\n",
    "        fn=lambda params: objective(params, X, y),  # 优化目标\n",
    "        space=param_space,  # 参数空间\n",
    "        algo=tpe.suggest,  # 使用TPE算法\n",
    "        max_evals=max_evals,  # 最大评估次数\n",
    "        trials=trials  # 记录每次评估的结果\n",
    "    )\n",
    "\n",
    "    return best_params, trials"
   ],
   "id": "fb0bbd61242dac48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:18:05.301476Z",
     "start_time": "2024-10-28T14:16:32.665144Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.132047\ttraining's ks: 0.823144\tvalid_1's binary_logloss: 0.18094\tvalid_1's ks: 0.519395\n",
      "[20]\ttraining's binary_logloss: 0.118563\ttraining's ks: 0.870877\tvalid_1's binary_logloss: 0.182574\tvalid_1's ks: 0.535411\n",
      "  0%|          | 0/10 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.132221\ttraining's ks: 0.828503\tvalid_1's binary_logloss: 0.17836\tvalid_1's ks: 0.5334\n",
      "[20]\ttraining's binary_logloss: 0.116955\ttraining's ks: 0.875865\tvalid_1's binary_logloss: 0.179604\tvalid_1's ks: 0.529141\n",
      "  0%|          | 0/10 [00:03<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.132483\ttraining's ks: 0.830632\tvalid_1's binary_logloss: 0.185361\tvalid_1's ks: 0.517343\n",
      "[20]\ttraining's binary_logloss: 0.119615\ttraining's ks: 0.87506\tvalid_1's binary_logloss: 0.188621\tvalid_1's ks: 0.522084\n",
      "  0%|          | 0/10 [00:05<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.131408\ttraining's ks: 0.843748\tvalid_1's binary_logloss: 0.177092\tvalid_1's ks: 0.515083\n",
      "[20]\ttraining's binary_logloss: 0.115308\ttraining's ks: 0.891091\tvalid_1's binary_logloss: 0.17876\tvalid_1's ks: 0.517065\n",
      "  0%|          | 0/10 [00:07<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.132643\ttraining's ks: 0.825433\tvalid_1's binary_logloss: 0.182057\tvalid_1's ks: 0.518585\n",
      "[20]\ttraining's binary_logloss: 0.115517\ttraining's ks: 0.878888\tvalid_1's binary_logloss: 0.182167\tvalid_1's ks: 0.516354\n",
      " 10%|█         | 1/10 [00:09<01:24,  9.41s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.214487\ttraining's ks: 0.584879\tvalid_1's binary_logloss: 0.219901\tvalid_1's ks: 0.551151\n",
      "[20]\ttraining's binary_logloss: 0.236247\ttraining's ks: 0.6077\tvalid_1's binary_logloss: 0.244612\tvalid_1's ks: 0.558739\n",
      " 10%|█         | 1/10 [00:10<01:24,  9.41s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.213774\ttraining's ks: 0.588587\tvalid_1's binary_logloss: 0.21841\tvalid_1's ks: 0.536705\n",
      "[20]\ttraining's binary_logloss: 0.235259\ttraining's ks: 0.608877\tvalid_1's binary_logloss: 0.242082\tvalid_1's ks: 0.549187\n",
      " 10%|█         | 1/10 [00:11<01:24,  9.41s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.213713\ttraining's ks: 0.593431\tvalid_1's binary_logloss: 0.228529\tvalid_1's ks: 0.513955\n",
      "[20]\ttraining's binary_logloss: 0.235532\ttraining's ks: 0.615408\tvalid_1's binary_logloss: 0.255646\tvalid_1's ks: 0.524801\n",
      " 10%|█         | 1/10 [00:12<01:24,  9.41s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.214983\ttraining's ks: 0.586756\tvalid_1's binary_logloss: 0.219284\tvalid_1's ks: 0.556798\n",
      "[20]\ttraining's binary_logloss: 0.236366\ttraining's ks: 0.616032\tvalid_1's binary_logloss: 0.242441\tvalid_1's ks: 0.564197\n",
      " 10%|█         | 1/10 [00:13<01:24,  9.41s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.213975\ttraining's ks: 0.59436\tvalid_1's binary_logloss: 0.224471\tvalid_1's ks: 0.523494\n",
      "[20]\ttraining's binary_logloss: 0.235453\ttraining's ks: 0.615633\tvalid_1's binary_logloss: 0.24935\tvalid_1's ks: 0.53366\n",
      " 20%|██        | 2/10 [00:14<00:54,  6.82s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.179666\ttraining's ks: 0.745319\tvalid_1's binary_logloss: 0.202891\tvalid_1's ks: 0.537794\n",
      "[20]\ttraining's binary_logloss: 0.188817\ttraining's ks: 0.807124\tvalid_1's binary_logloss: 0.222868\tvalid_1's ks: 0.5232\n",
      " 20%|██        | 2/10 [00:15<00:54,  6.82s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.1795\ttraining's ks: 0.753049\tvalid_1's binary_logloss: 0.201718\tvalid_1's ks: 0.530089\n",
      "[20]\ttraining's binary_logloss: 0.189983\ttraining's ks: 0.798358\tvalid_1's binary_logloss: 0.22231\tvalid_1's ks: 0.5414\n",
      " 20%|██        | 2/10 [00:17<00:54,  6.82s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.179907\ttraining's ks: 0.742088\tvalid_1's binary_logloss: 0.208456\tvalid_1's ks: 0.52553\n",
      "[20]\ttraining's binary_logloss: 0.190993\ttraining's ks: 0.790324\tvalid_1's binary_logloss: 0.233555\tvalid_1's ks: 0.514419\n",
      " 20%|██        | 2/10 [00:19<00:54,  6.82s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.177573\ttraining's ks: 0.761422\tvalid_1's binary_logloss: 0.199219\tvalid_1's ks: 0.530947\n",
      "[20]\ttraining's binary_logloss: 0.187181\ttraining's ks: 0.811721\tvalid_1's binary_logloss: 0.217727\tvalid_1's ks: 0.543281\n",
      " 20%|██        | 2/10 [00:20<00:54,  6.82s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.177582\ttraining's ks: 0.759198\tvalid_1's binary_logloss: 0.20436\tvalid_1's ks: 0.508658\n",
      "[20]\ttraining's binary_logloss: 0.188182\ttraining's ks: 0.804734\tvalid_1's binary_logloss: 0.225835\tvalid_1's ks: 0.51336\n",
      " 30%|███       | 3/10 [00:22<00:52,  7.44s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.145735\ttraining's ks: 0.630688\tvalid_1's binary_logloss: 0.161469\tvalid_1's ks: 0.557245\n",
      "[20]\ttraining's binary_logloss: 0.13431\ttraining's ks: 0.668243\tvalid_1's binary_logloss: 0.15909\tvalid_1's ks: 0.567803\n",
      "[30]\ttraining's binary_logloss: 0.128396\ttraining's ks: 0.695817\tvalid_1's binary_logloss: 0.159546\tvalid_1's ks: 0.564373\n",
      "[40]\ttraining's binary_logloss: 0.123459\ttraining's ks: 0.718915\tvalid_1's binary_logloss: 0.160369\tvalid_1's ks: 0.561268\n",
      " 30%|███       | 3/10 [00:24<00:52,  7.44s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.146759\ttraining's ks: 0.633344\tvalid_1's binary_logloss: 0.162049\tvalid_1's ks: 0.551392\n",
      "[20]\ttraining's binary_logloss: 0.134101\ttraining's ks: 0.67123\tvalid_1's binary_logloss: 0.159306\tvalid_1's ks: 0.565038\n",
      "[30]\ttraining's binary_logloss: 0.129273\ttraining's ks: 0.693778\tvalid_1's binary_logloss: 0.159116\tvalid_1's ks: 0.561097\n",
      "[40]\ttraining's binary_logloss: 0.123991\ttraining's ks: 0.722494\tvalid_1's binary_logloss: 0.15977\tvalid_1's ks: 0.557533\n",
      " 30%|███       | 3/10 [00:25<00:52,  7.44s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.145675\ttraining's ks: 0.638421\tvalid_1's binary_logloss: 0.166092\tvalid_1's ks: 0.52823\n",
      "[20]\ttraining's binary_logloss: 0.134454\ttraining's ks: 0.676123\tvalid_1's binary_logloss: 0.16398\tvalid_1's ks: 0.539552\n",
      "[30]\ttraining's binary_logloss: 0.128136\ttraining's ks: 0.703323\tvalid_1's binary_logloss: 0.163908\tvalid_1's ks: 0.540069\n",
      "[40]\ttraining's binary_logloss: 0.122436\ttraining's ks: 0.734254\tvalid_1's binary_logloss: 0.164075\tvalid_1's ks: 0.539428\n",
      " 30%|███       | 3/10 [00:27<00:52,  7.44s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.146999\ttraining's ks: 0.639131\tvalid_1's binary_logloss: 0.161781\tvalid_1's ks: 0.534029\n",
      "[20]\ttraining's binary_logloss: 0.134896\ttraining's ks: 0.680393\tvalid_1's binary_logloss: 0.159936\tvalid_1's ks: 0.541416\n",
      "[30]\ttraining's binary_logloss: 0.12814\ttraining's ks: 0.711198\tvalid_1's binary_logloss: 0.159884\tvalid_1's ks: 0.547957\n",
      "[40]\ttraining's binary_logloss: 0.122375\ttraining's ks: 0.734756\tvalid_1's binary_logloss: 0.160984\tvalid_1's ks: 0.549657\n",
      " 30%|███       | 3/10 [00:29<00:52,  7.44s/trial, best loss: -0.5052191623951107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                     \n",
      "[10]\ttraining's binary_logloss: 0.145421\ttraining's ks: 0.640798\tvalid_1's binary_logloss: 0.164646\tvalid_1's ks: 0.527926\n",
      "[20]\ttraining's binary_logloss: 0.134623\ttraining's ks: 0.67468\tvalid_1's binary_logloss: 0.161951\tvalid_1's ks: 0.537943\n",
      "[30]\ttraining's binary_logloss: 0.12688\ttraining's ks: 0.710286\tvalid_1's binary_logloss: 0.161947\tvalid_1's ks: 0.545312\n",
      "[40]\ttraining's binary_logloss: 0.122603\ttraining's ks: 0.725667\tvalid_1's binary_logloss: 0.161729\tvalid_1's ks: 0.548307\n",
      " 40%|████      | 4/10 [00:31<00:47,  7.88s/trial, best loss: -0.542467198507184] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.166138\ttraining's ks: 0.81367\tvalid_1's binary_logloss: 0.202969\tvalid_1's ks: 0.544781\n",
      "[20]\ttraining's binary_logloss: 0.159156\ttraining's ks: 0.87561\tvalid_1's binary_logloss: 0.212896\tvalid_1's ks: 0.54234\n",
      " 40%|████      | 4/10 [00:32<00:47,  7.88s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.168953\ttraining's ks: 0.811478\tvalid_1's binary_logloss: 0.203667\tvalid_1's ks: 0.537082\n",
      "[20]\ttraining's binary_logloss: 0.166984\ttraining's ks: 0.859887\tvalid_1's binary_logloss: 0.214325\tvalid_1's ks: 0.548263\n",
      " 40%|████      | 4/10 [00:34<00:47,  7.88s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.169376\ttraining's ks: 0.801221\tvalid_1's binary_logloss: 0.213521\tvalid_1's ks: 0.508844\n",
      "[20]\ttraining's binary_logloss: 0.165729\ttraining's ks: 0.848827\tvalid_1's binary_logloss: 0.227123\tvalid_1's ks: 0.516689\n",
      " 40%|████      | 4/10 [00:36<00:47,  7.88s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.1683\ttraining's ks: 0.8094\tvalid_1's binary_logloss: 0.205899\tvalid_1's ks: 0.506638\n",
      "[20]\ttraining's binary_logloss: 0.163045\ttraining's ks: 0.861196\tvalid_1's binary_logloss: 0.215556\tvalid_1's ks: 0.508997\n",
      " 40%|████      | 4/10 [00:37<00:47,  7.88s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.168506\ttraining's ks: 0.798316\tvalid_1's binary_logloss: 0.209434\tvalid_1's ks: 0.509315\n",
      "[20]\ttraining's binary_logloss: 0.16108\ttraining's ks: 0.862474\tvalid_1's binary_logloss: 0.218638\tvalid_1's ks: 0.518\n",
      " 50%|█████     | 5/10 [00:39<00:40,  8.16s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.197399\ttraining's ks: 0.687967\tvalid_1's binary_logloss: 0.213139\tvalid_1's ks: 0.546858\n",
      "[20]\ttraining's binary_logloss: 0.219092\ttraining's ks: 0.731082\tvalid_1's binary_logloss: 0.24178\tvalid_1's ks: 0.548781\n",
      " 50%|█████     | 5/10 [00:41<00:40,  8.16s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.195379\ttraining's ks: 0.701413\tvalid_1's binary_logloss: 0.212213\tvalid_1's ks: 0.514367\n",
      "[20]\ttraining's binary_logloss: 0.216103\ttraining's ks: 0.731382\tvalid_1's binary_logloss: 0.239227\tvalid_1's ks: 0.525929\n",
      " 50%|█████     | 5/10 [00:42<00:40,  8.16s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.196292\ttraining's ks: 0.685995\tvalid_1's binary_logloss: 0.219764\tvalid_1's ks: 0.519642\n",
      "[20]\ttraining's binary_logloss: 0.218967\ttraining's ks: 0.713187\tvalid_1's binary_logloss: 0.252203\tvalid_1's ks: 0.522525\n",
      " 50%|█████     | 5/10 [00:44<00:40,  8.16s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.197402\ttraining's ks: 0.696626\tvalid_1's binary_logloss: 0.212788\tvalid_1's ks: 0.534346\n",
      "[20]\ttraining's binary_logloss: 0.218627\ttraining's ks: 0.726613\tvalid_1's binary_logloss: 0.240173\tvalid_1's ks: 0.542634\n",
      " 50%|█████     | 5/10 [00:45<00:40,  8.16s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.195856\ttraining's ks: 0.698309\tvalid_1's binary_logloss: 0.216839\tvalid_1's ks: 0.512175\n",
      "[20]\ttraining's binary_logloss: 0.216064\ttraining's ks: 0.739069\tvalid_1's binary_logloss: 0.244895\tvalid_1's ks: 0.51806\n",
      " 60%|██████    | 6/10 [00:47<00:31,  7.94s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.200225\ttraining's ks: 0.694173\tvalid_1's binary_logloss: 0.215864\tvalid_1's ks: 0.547375\n",
      "[20]\ttraining's binary_logloss: 0.225007\ttraining's ks: 0.736295\tvalid_1's binary_logloss: 0.246967\tvalid_1's ks: 0.54924\n",
      " 60%|██████    | 6/10 [00:48<00:31,  7.94s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.200602\ttraining's ks: 0.697095\tvalid_1's binary_logloss: 0.214688\tvalid_1's ks: 0.535106\n",
      "[20]\ttraining's binary_logloss: 0.224942\ttraining's ks: 0.739759\tvalid_1's binary_logloss: 0.245224\tvalid_1's ks: 0.545287\n",
      " 60%|██████    | 6/10 [00:50<00:31,  7.94s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.200731\ttraining's ks: 0.696456\tvalid_1's binary_logloss: 0.222905\tvalid_1's ks: 0.505515\n",
      "[20]\ttraining's binary_logloss: 0.226129\ttraining's ks: 0.737279\tvalid_1's binary_logloss: 0.258569\tvalid_1's ks: 0.518196\n",
      " 60%|██████    | 6/10 [00:51<00:31,  7.94s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.200395\ttraining's ks: 0.705183\tvalid_1's binary_logloss: 0.213869\tvalid_1's ks: 0.539488\n",
      "[20]\ttraining's binary_logloss: 0.225425\ttraining's ks: 0.742098\tvalid_1's binary_logloss: 0.243482\tvalid_1's ks: 0.56208\n",
      " 60%|██████    | 6/10 [00:52<00:31,  7.94s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.199856\ttraining's ks: 0.696936\tvalid_1's binary_logloss: 0.218858\tvalid_1's ks: 0.514091\n",
      "[20]\ttraining's binary_logloss: 0.223897\ttraining's ks: 0.745992\tvalid_1's binary_logloss: 0.250602\tvalid_1's ks: 0.533917\n",
      " 70%|███████   | 7/10 [00:54<00:23,  7.67s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.173179\ttraining's ks: 0.724316\tvalid_1's binary_logloss: 0.185529\tvalid_1's ks: 0.531442\n",
      "[20]\ttraining's binary_logloss: 0.160345\ttraining's ks: 0.7684\tvalid_1's binary_logloss: 0.179973\tvalid_1's ks: 0.5404\n",
      "[30]\ttraining's binary_logloss: 0.153506\ttraining's ks: 0.798752\tvalid_1's binary_logloss: 0.17893\tvalid_1's ks: 0.539864\n",
      "[40]\ttraining's binary_logloss: 0.14911\ttraining's ks: 0.821063\tvalid_1's binary_logloss: 0.179323\tvalid_1's ks: 0.544023\n",
      "[50]\ttraining's binary_logloss: 0.146134\ttraining's ks: 0.838503\tvalid_1's binary_logloss: 0.18032\tvalid_1's ks: 0.547652\n",
      " 70%|███████   | 7/10 [00:58<00:23,  7.67s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.173289\ttraining's ks: 0.732214\tvalid_1's binary_logloss: 0.18537\tvalid_1's ks: 0.529088\n",
      "[20]\ttraining's binary_logloss: 0.160554\ttraining's ks: 0.765476\tvalid_1's binary_logloss: 0.179931\tvalid_1's ks: 0.54384\n",
      "[30]\ttraining's binary_logloss: 0.153775\ttraining's ks: 0.791911\tvalid_1's binary_logloss: 0.178557\tvalid_1's ks: 0.549639\n",
      "[40]\ttraining's binary_logloss: 0.149482\ttraining's ks: 0.813081\tvalid_1's binary_logloss: 0.179049\tvalid_1's ks: 0.550139\n",
      " 70%|███████   | 7/10 [01:01<00:23,  7.67s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.172912\ttraining's ks: 0.73351\tvalid_1's binary_logloss: 0.18625\tvalid_1's ks: 0.493803\n",
      "[20]\ttraining's binary_logloss: 0.159902\ttraining's ks: 0.773911\tvalid_1's binary_logloss: 0.181797\tvalid_1's ks: 0.52563\n",
      "[30]\ttraining's binary_logloss: 0.153124\ttraining's ks: 0.805394\tvalid_1's binary_logloss: 0.181906\tvalid_1's ks: 0.51906\n",
      "[40]\ttraining's binary_logloss: 0.148937\ttraining's ks: 0.81874\tvalid_1's binary_logloss: 0.183204\tvalid_1's ks: 0.52466\n",
      " 70%|███████   | 7/10 [01:05<00:23,  7.67s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.173115\ttraining's ks: 0.74297\tvalid_1's binary_logloss: 0.185065\tvalid_1's ks: 0.513378\n",
      "[20]\ttraining's binary_logloss: 0.160661\ttraining's ks: 0.779867\tvalid_1's binary_logloss: 0.179688\tvalid_1's ks: 0.519583\n",
      "[30]\ttraining's binary_logloss: 0.154028\ttraining's ks: 0.807658\tvalid_1's binary_logloss: 0.178534\tvalid_1's ks: 0.523595\n",
      "[40]\ttraining's binary_logloss: 0.150159\ttraining's ks: 0.825411\tvalid_1's binary_logloss: 0.178508\tvalid_1's ks: 0.531812\n",
      "[50]\ttraining's binary_logloss: 0.147486\ttraining's ks: 0.837393\tvalid_1's binary_logloss: 0.179573\tvalid_1's ks: 0.531829\n",
      " 70%|███████   | 7/10 [01:10<00:23,  7.67s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.172718\ttraining's ks: 0.730949\tvalid_1's binary_logloss: 0.186319\tvalid_1's ks: 0.514285\n",
      "[20]\ttraining's binary_logloss: 0.159798\ttraining's ks: 0.77423\tvalid_1's binary_logloss: 0.18133\tvalid_1's ks: 0.521653\n",
      "[30]\ttraining's binary_logloss: 0.153063\ttraining's ks: 0.803397\tvalid_1's binary_logloss: 0.180586\tvalid_1's ks: 0.528153\n",
      "[40]\ttraining's binary_logloss: 0.148794\ttraining's ks: 0.819422\tvalid_1's binary_logloss: 0.181428\tvalid_1's ks: 0.527373\n",
      " 80%|████████  | 8/10 [01:14<00:23, 11.64s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.174111\ttraining's ks: 0.824853\tvalid_1's binary_logloss: 0.219822\tvalid_1's ks: 0.528871\n",
      "[20]\ttraining's binary_logloss: 0.155647\ttraining's ks: 0.874313\tvalid_1's binary_logloss: 0.218351\tvalid_1's ks: 0.528818\n",
      " 80%|████████  | 8/10 [01:16<00:23, 11.64s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.173087\ttraining's ks: 0.821479\tvalid_1's binary_logloss: 0.220145\tvalid_1's ks: 0.501784\n",
      "[20]\ttraining's binary_logloss: 0.155666\ttraining's ks: 0.879054\tvalid_1's binary_logloss: 0.219198\tvalid_1's ks: 0.515095\n",
      " 80%|████████  | 8/10 [01:18<00:23, 11.64s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.169749\ttraining's ks: 0.835833\tvalid_1's binary_logloss: 0.225045\tvalid_1's ks: 0.51045\n",
      "[20]\ttraining's binary_logloss: 0.155883\ttraining's ks: 0.867451\tvalid_1's binary_logloss: 0.228367\tvalid_1's ks: 0.510167\n",
      " 80%|████████  | 8/10 [01:20<00:23, 11.64s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.17056\ttraining's ks: 0.825311\tvalid_1's binary_logloss: 0.215565\tvalid_1's ks: 0.516584\n",
      "[20]\ttraining's binary_logloss: 0.150152\ttraining's ks: 0.888252\tvalid_1's binary_logloss: 0.213688\tvalid_1's ks: 0.50942\n",
      " 80%|████████  | 8/10 [01:22<00:23, 11.64s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.170036\ttraining's ks: 0.830834\tvalid_1's binary_logloss: 0.219166\tvalid_1's ks: 0.517535\n",
      "[20]\ttraining's binary_logloss: 0.152126\ttraining's ks: 0.887679\tvalid_1's binary_logloss: 0.214403\tvalid_1's ks: 0.541163\n",
      " 90%|█████████ | 9/10 [01:24<00:11, 11.13s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.23863\ttraining's ks: 0.632269\tvalid_1's binary_logloss: 0.248674\tvalid_1's ks: 0.563609\n",
      "[20]\ttraining's binary_logloss: 0.266635\ttraining's ks: 0.681848\tvalid_1's binary_logloss: 0.282418\tvalid_1's ks: 0.56228\n",
      " 90%|█████████ | 9/10 [01:25<00:11, 11.13s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.238384\ttraining's ks: 0.642321\tvalid_1's binary_logloss: 0.24722\tvalid_1's ks: 0.531948\n",
      "[20]\ttraining's binary_logloss: 0.265809\ttraining's ks: 0.686041\tvalid_1's binary_logloss: 0.280148\tvalid_1's ks: 0.54327\n",
      " 90%|█████████ | 9/10 [01:27<00:11, 11.13s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.238627\ttraining's ks: 0.634176\tvalid_1's binary_logloss: 0.257827\tvalid_1's ks: 0.518107\n",
      "[20]\ttraining's binary_logloss: 0.266602\ttraining's ks: 0.678519\tvalid_1's binary_logloss: 0.295284\tvalid_1's ks: 0.514949\n",
      " 90%|█████████ | 9/10 [01:28<00:11, 11.13s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.240618\ttraining's ks: 0.638914\tvalid_1's binary_logloss: 0.248452\tvalid_1's ks: 0.534923\n",
      "[20]\ttraining's binary_logloss: 0.26789\ttraining's ks: 0.682527\tvalid_1's binary_logloss: 0.279088\tvalid_1's ks: 0.546545\n",
      " 90%|█████████ | 9/10 [01:29<00:11, 11.13s/trial, best loss: -0.542467198507184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds                    \n",
      "[10]\ttraining's binary_logloss: 0.238619\ttraining's ks: 0.63739\tvalid_1's binary_logloss: 0.254265\tvalid_1's ks: 0.5236\n",
      "[20]\ttraining's binary_logloss: 0.266104\ttraining's ks: 0.683943\tvalid_1's binary_logloss: 0.288466\tvalid_1's ks: 0.540821\n",
      "100%|██████████| 10/10 [01:31<00:00,  9.11s/trial, best loss: -0.542467198507184]\n",
      "Best parameters found: {'colsample_bytree': 0.6983157656158572, 'learning_rate': 0.1705732511631721, 'max_depth': 4, 'min_child_weight': 9.775174703305787, 'num_leaves': 23, 'reg_alpha': 0.6014275790836761, 'reg_lambda': 0.30676387849859477, 'scale_pos_weight': 1.0099553852611183, 'subsample': 0.8925238455520927}\n"
     ]
    }
   ],
   "execution_count": 24,
   "source": [
    "# 读取数据\n",
    "df_target = loader.to_concat_df('TARGET')\n",
    "df_flat = pd.read_csv(f'{dir_preprocess}/df_flat.csv')\n",
    "df_flat = df_flat.merge(df_target, left_on=['CUST_NO', 'is_train'], right_on=['CUST_NO', 'is_train'], how='inner')\n",
    "df_flat.drop(columns=['DATA_DAT', 'CARD_NO', 'CUST_NO'], inplace=True)\n",
    "\n",
    "X = df_flat[df_flat['is_train'] == 1]\n",
    "y = X.pop(\"FLAG\")  # 目标标签列\n",
    "\n",
    "# 执行贝叶斯优化\n",
    "best_params, trials = bayesian_optimize_lgbm(X, y, param_space, max_evals=10)\n",
    "\n",
    "print(\"Best parameters found:\", best_params)"
   ],
   "id": "467c020715be8573"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:18:09.315110Z",
     "start_time": "2024-10-28T14:18:09.302873Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 25,
   "source": [
    "# 5折交叉验证\n",
    "def lgb_5_fold(X, y, best_params, n_folds=5):\n",
    "    best_params.update({\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'verbose': -1,\n",
    "        'n_estimators': 10000,  # 和贝叶斯优化期间保持一致\n",
    "        'early_stopping_round': 20\n",
    "    })\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    fold_scores = []\n",
    "    final_predictions = np.zeros(len(X))  # 用于存储每一折的预测结果\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        # 训练模型\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "        model = lgb.train(best_params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_valid],\n",
    "                          feval=lgb_ks_eval,\n",
    "                          callbacks=[lgb.early_stopping(stopping_rounds=50),\n",
    "                                     lgb.log_evaluation(10)])\n",
    "\n",
    "        # 保存模型\n",
    "        model_path = f\"{dir_model}/lgbm_fold_{fold + 1}.bin\"\n",
    "        model.save_model(model_path)\n",
    "        print(f\"Model for fold {fold + 1} saved at {model_path}\")\n",
    "\n",
    "        # 验证集预测\n",
    "        y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "        # 计算KS\n",
    "        score = ks_stat(y_valid, y_pred)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "        # 将每一折的预测结果保存到对应的索引位置\n",
    "        final_predictions[valid_idx] = y_pred\n",
    "\n",
    "        print(f\"Fold {fold + 1} - Score: {score:.4f}\")\n",
    "\n",
    "    # 最终综合预测结果的评分\n",
    "    overall_score = ks_stat(y, final_predictions)\n",
    "\n",
    "    print(f\"\\nOverall Score: {overall_score:.4f}\")\n",
    "\n",
    "    return overall_score"
   ],
   "id": "967cc4696e9445aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:18:19.136416Z",
     "start_time": "2024-10-28T14:18:10.170268Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.157059\ttraining's ks: 0.576152\tvalid_1's binary_logloss: 0.163124\tvalid_1's ks: 0.561215\n",
      "[20]\ttraining's binary_logloss: 0.149618\ttraining's ks: 0.595574\tvalid_1's binary_logloss: 0.15999\tvalid_1's ks: 0.553792\n",
      "[30]\ttraining's binary_logloss: 0.145429\ttraining's ks: 0.606795\tvalid_1's binary_logloss: 0.159353\tvalid_1's ks: 0.557227\n",
      "Model for fold 1 saved at /Users/z/Data/Contest/2024/sh/dummy/model/lgbm_fold_1.bin\n",
      "Fold 1 - Score: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.156688\ttraining's ks: 0.577266\tvalid_1's binary_logloss: 0.163487\tvalid_1's ks: 0.543723\n",
      "[20]\ttraining's binary_logloss: 0.14903\ttraining's ks: 0.603021\tvalid_1's binary_logloss: 0.159818\tvalid_1's ks: 0.548952\n",
      "[30]\ttraining's binary_logloss: 0.144621\ttraining's ks: 0.613624\tvalid_1's binary_logloss: 0.15864\tvalid_1's ks: 0.553868\n",
      "[40]\ttraining's binary_logloss: 0.140997\ttraining's ks: 0.6388\tvalid_1's binary_logloss: 0.158075\tvalid_1's ks: 0.555845\n",
      "[50]\ttraining's binary_logloss: 0.138129\ttraining's ks: 0.654463\tvalid_1's binary_logloss: 0.158351\tvalid_1's ks: 0.551328\n",
      "Model for fold 2 saved at /Users/z/Data/Contest/2024/sh/dummy/model/lgbm_fold_2.bin\n",
      "Fold 2 - Score: 0.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.156697\ttraining's ks: 0.583152\tvalid_1's binary_logloss: 0.166882\tvalid_1's ks: 0.517907\n",
      "[20]\ttraining's binary_logloss: 0.149197\ttraining's ks: 0.601976\tvalid_1's binary_logloss: 0.162898\tvalid_1's ks: 0.535064\n",
      "[30]\ttraining's binary_logloss: 0.145573\ttraining's ks: 0.61526\tvalid_1's binary_logloss: 0.161948\tvalid_1's ks: 0.542605\n",
      "[40]\ttraining's binary_logloss: 0.142556\ttraining's ks: 0.628371\tvalid_1's binary_logloss: 0.16142\tvalid_1's ks: 0.540941\n",
      "[50]\ttraining's binary_logloss: 0.139811\ttraining's ks: 0.642123\tvalid_1's binary_logloss: 0.161107\tvalid_1's ks: 0.54724\n",
      "[60]\ttraining's binary_logloss: 0.136972\ttraining's ks: 0.657321\tvalid_1's binary_logloss: 0.161233\tvalid_1's ks: 0.547164\n",
      "[70]\ttraining's binary_logloss: 0.134708\ttraining's ks: 0.661718\tvalid_1's binary_logloss: 0.161718\tvalid_1's ks: 0.540082\n",
      "Model for fold 3 saved at /Users/z/Data/Contest/2024/sh/dummy/model/lgbm_fold_3.bin\n",
      "Fold 3 - Score: 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.157008\ttraining's ks: 0.574982\tvalid_1's binary_logloss: 0.163026\tvalid_1's ks: 0.543487\n",
      "[20]\ttraining's binary_logloss: 0.149493\ttraining's ks: 0.597475\tvalid_1's binary_logloss: 0.159274\tvalid_1's ks: 0.552869\n",
      "[30]\ttraining's binary_logloss: 0.145258\ttraining's ks: 0.609912\tvalid_1's binary_logloss: 0.158365\tvalid_1's ks: 0.557344\n",
      "[40]\ttraining's binary_logloss: 0.141428\ttraining's ks: 0.628169\tvalid_1's binary_logloss: 0.158344\tvalid_1's ks: 0.562103\n",
      "[50]\ttraining's binary_logloss: 0.137799\ttraining's ks: 0.639677\tvalid_1's binary_logloss: 0.15854\tvalid_1's ks: 0.562391\n",
      "[60]\ttraining's binary_logloss: 0.135215\ttraining's ks: 0.654129\tvalid_1's binary_logloss: 0.158815\tvalid_1's ks: 0.556127\n",
      "Model for fold 4 saved at /Users/z/Data/Contest/2024/sh/dummy/model/lgbm_fold_4.bin\n",
      "Fold 4 - Score: 0.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's binary_logloss: 0.156165\ttraining's ks: 0.567873\tvalid_1's binary_logloss: 0.166483\tvalid_1's ks: 0.531536\n",
      "[20]\ttraining's binary_logloss: 0.148325\ttraining's ks: 0.595583\tvalid_1's binary_logloss: 0.162978\tvalid_1's ks: 0.530982\n",
      "[30]\ttraining's binary_logloss: 0.143799\ttraining's ks: 0.613765\tvalid_1's binary_logloss: 0.162249\tvalid_1's ks: 0.535129\n",
      "[40]\ttraining's binary_logloss: 0.141151\ttraining's ks: 0.621926\tvalid_1's binary_logloss: 0.162119\tvalid_1's ks: 0.540969\n",
      "[50]\ttraining's binary_logloss: 0.138316\ttraining's ks: 0.634735\tvalid_1's binary_logloss: 0.162403\tvalid_1's ks: 0.537181\n",
      "Model for fold 5 saved at /Users/z/Data/Contest/2024/sh/dummy/model/lgbm_fold_5.bin\n",
      "Fold 5 - Score: 0.5428\n",
      "\n",
      "Overall Score: 0.5485\n",
      "Best score: 0.5485360295890676\n"
     ]
    }
   ],
   "execution_count": 26,
   "source": [
    "# 执行5折交叉验证\n",
    "best_score = lgb_5_fold(X, y, best_params)\n",
    "print(f\"Best score: {best_score}\")\n"
   ],
   "id": "c7402558a4582707"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best seed found: 0 with lowest KS std: 0.009036162651410237\n",
      "0\n",
      "{0: (0.5519935649537354, 0.009036162651410237), 42: (0.5501777084193054, 0.029194183607442168), 100: (0.5534339207343374, 0.021856339442777126), 2023: (0.5484132032355762, 0.012979645226222662)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "def find_optimal_seed(X, y, param_space, n_folds=5, seed_list=[0, 42, 100, 2023]):\n",
    "    best_seed = None\n",
    "    lowest_std = float('inf')\n",
    "    seed_scores = {}\n",
    "\n",
    "    for seed in seed_list:\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_idx, valid_idx in skf.split(X, y):\n",
    "            X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "            y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "            # 使用与之前一致的参数和模型训练方法\n",
    "            model = lgb.LGBMClassifier(**param_space)  # 使用参数构建模型\n",
    "            model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50, verbose=False)\n",
    "            \n",
    "            y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "            ks = ks_stat(y_valid, y_pred)\n",
    "            fold_scores.append(ks)\n",
    "\n",
    "        # 计算该种子下的折间KS值的标准差\n",
    "        std_ks = np.std(fold_scores)\n",
    "        seed_scores[seed] = (np.mean(fold_scores), std_ks)\n",
    "\n",
    "        if std_ks < lowest_std:\n",
    "            best_seed = seed\n",
    "            lowest_std = std_ks\n",
    "\n",
    "    print(f\"Best seed found: {best_seed} with lowest KS std: {lowest_std}\")\n",
    "    return best_seed, seed_scores\n",
    "\n",
    "\n",
    "optimal_seed, seed_scores = find_optimal_seed(X, y, best_params, n_folds=5, seed_list=[0, 42, 100, 2023])\n",
    "\n",
    "print(optimal_seed)\n",
    "print(seed_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-28T14:15:39.102466Z",
     "start_time": "2024-10-28T14:15:07.192007Z"
    }
   },
   "id": "40b4c8da6ccf2a1c",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 测试集预测并生成结果文件\n",
    "def predict_test_set(test_data, n_folds=5, output_file='upload.csv'):\n",
    "    test_predictions = np.zeros(len(test_data))\n",
    "\n",
    "    # 依次加载每一折的模型进行预测\n",
    "    for fold in range(n_folds):\n",
    "        model_path = f\"{dir_model}/lgbm_dart_fold_{fold + 1}.bin\"\n",
    "        model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "        # 对测试集进行预测，并将每一折的预测加总\n",
    "        test_predictions += model.predict(test_data)\n",
    "\n",
    "    # 平均每一折的预测\n",
    "    test_predictions /= n_folds\n",
    "\n",
    "    # 生成预测文件\n",
    "    submission = pd.DataFrame({'CUST_NO': test_data.index, 'PRED': test_predictions})\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Test predictions saved to {output_file}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:19:17.442312Z",
     "start_time": "2024-10-28T14:19:17.437879Z"
    }
   },
   "id": "fa86b3eaf4ad5a9d",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9e91bbb44f99635f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
